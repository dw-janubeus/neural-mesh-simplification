# Optimized configuration for neural mesh simplification training
# This configuration is designed to maximize GPU utilization and training speed

# Model parameters
model:
  input_dim: 3
  hidden_dim: 128     # feature dimension for point sampler and face classifier
  edge_hidden_dim: 64 # feature dimension for edge predictor
  num_layers: 3       # number of convolutional layers
  k: 15              # number of neighbors for graph construction
  edge_k: 15         # number of neighbors for edge features  
  target_ratio: 0.5  # mesh simplification ratio

# Optimized training parameters
training:
  learning_rate: 2.0e-4      # Increased from 1e-5 for faster convergence
  weight_decay: 1e-4         # Reduced weight decay for better performance
  batch_size: 8              # Increased from 2 for better GPU utilization
  num_epochs: 50             # Increased epochs since training is faster
  early_stopping_patience: 10 # Reduced patience since epochs are faster
  checkpoint_dir: data/checkpoints_optimized
  
  # Optimized training settings
  optimizer: adamw           # Better optimizer than Adam
  scheduler: cosine          # Cosine annealing scheduler
  use_augmentation: true     # Data augmentation for better generalization

# Data parameters - optimized for performance  
data:
  data_dir: data/processed                    # Fallback directory
  optimized_data_dir: data/processed_optimized # Primary optimized data directory
  val_split: 0.2

# Loss weights
loss:
  lambda_c: 1.0 # chamfer distance weight
  lambda_e: 1.0 # edge preservation weight  
  lambda_o: 1.0 # normal consistency weight

# Performance optimization settings
mixed_precision: true        # Enable mixed precision training for speed
gradient_accumulation_steps: 2 # Effective batch size = batch_size * accumulation_steps = 16
compile_model: false         # Disable torch.compile for compatibility (enable if PyTorch 2.0+)

# Resource monitoring
monitor_resources: true

# Debug settings (comment out for full training)
# debug_subset_size: 100     # Use only 100 samples for quick testing
